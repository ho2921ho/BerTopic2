{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf256a88",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\user-pc\\miniconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User-Pc\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading keybert-0.6.0-py2.py3-none-any.whl (22 kB)\n",
      "Collecting rich>=10.4.0\n",
      "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
      "     -------------------------------------- 235.6/235.6 KB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from keybert) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from keybert) (1.21.5)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from keybert) (2.2.2)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "     ---------------------------------------- 51.1/51.1 KB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from rich>=10.4.0->keybert) (2.11.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.9.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.21.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.12.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.63.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (3.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.8.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (1.11.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (0.1.97)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (5.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.4.24)\n",
      "Requirement already satisfied: colorama in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (0.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user-pc\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2021.10.8)\n",
      "Installing collected packages: commonmark, rich, keybert\n",
      "Successfully installed commonmark-0.9.1 keybert-0.6.0 rich-12.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99556a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fe5574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'news-8-5-2019.pickle'\n",
    "with open('C:/Users/Notebiz003/BerTopic/news/' + name, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4353db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05859a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for x in df['index']:\n",
    "    tmp = x.split('/')\n",
    "    if len(tmp[0]) == 1:\n",
    "        tmp[0] = '0'+tmp[0]\n",
    "    if len(tmp[1]) == 1:\n",
    "        tmp[1] = '0'+tmp[1]\n",
    "    tmp = tmp[2] + tmp[0] + tmp[1]\n",
    "    idx.append(''.join(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e89932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index'] = idx\n",
    "df = df.rename({'index':'일자',0:'news'},axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a96c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2key(cleaned_content):\n",
    "    \n",
    "    kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "    keywords = kw_model.extract_keywords(doc)\n",
    "    \n",
    "    n2_kwd = kw_model.extract_keywords(cleaned_content, keyphrase_ngram_range=(2, 2), stop_words='english',\n",
    "                                  use_mmr=True, diversity=0.7, top_n=100)\n",
    "\n",
    "    n1_kwd = kw_model.extract_keywords(cleaned_content, keyphrase_ngram_range=(1, 1), stop_words='english',\n",
    "                                  use_mmr=True, diversity=0.7, top_n=50)\n",
    "    for idx,i in enumerate(n2_kwd):\n",
    "        n2_kwd[idx] = i[0]\n",
    "    for idx,i in enumerate(n1_kwd):\n",
    "        n1_kwd[idx] = i[0]  \n",
    "\n",
    "    n1_kwd.extend(n2_kwd)\n",
    "    kwd = n1_kwd\n",
    "    return kwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a4d3726",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:49<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "news = df.iloc[0,:]['news']\n",
    "date = df.iloc[0,:]['일자']\n",
    "tmp_dict = dict()\n",
    "\n",
    "tmp = []\n",
    "for doc in tqdm(news):\n",
    "    cleaned_content = re.sub(r'[^\\.\\?\\!\\w\\d\\s]','',doc) # 문장단위로 끊기\n",
    "    cleaned_content = cleaned_content.replace('\\n',' ')\n",
    "    cleaned_content = cleaned_content.lower()\n",
    "    kwd = doc2key(cleaned_content)\n",
    "    tmp.append(kwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61a27bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict[date] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ead00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8b5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88e88087",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df['일자'] = [date for x in range(len(tmp))]\n",
    "tmp_df = tmp_df.rename({date:'키워드'},axis = 1)\n",
    "tmp_df = tmp_df[['일자','키워드']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2549ad0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>키워드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[newspaper, layoffs, buzzfeed, losses, pew, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[debit, houstonbusiness, ecommerce, p2p, rates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[fintechs, neobankstyle, venture, londonbased,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[nonpayment, invoices, financing, factoring, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[ippb, postal, delhi, crore, payments, infrast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[goldman, banks, marcus, consumer, markets, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[inventing, prototypes, changemakers, venture,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[venezuelas, cryptocurrency, sanctions, exchan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[cryptocurrencyfocused, hedge, investing, liqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[entrepreneurs, purushothaman, newsmarket, fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[forbes, httpswww, comsiteslizfrazierpeck20190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[entrepreneurship, senegal, smeat, consulting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[dell, emc, dellemc, recession, merging, share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[sandbox, utahs, wyoming, authorization, requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[comnewspartnershipsacquisitions2019amexdigita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[cookies, ft, sites, ads, use, secure, data, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[accountants, exemption, qualifications, chart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[banks, broker, shareholders, refinitivs, reut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[shanghaibased, fanlis, zhu, rebates, venture,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[tuition, institutions, grants, financial, req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[cookies, ft, sites, ads, use, secure, data, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[audiomasking, eavesdrop, smartphones, mask, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[airtel, delhibased, bharti, reliance, 2g, cel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[forbes, httpswww, comsitessuzannerowankellehe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[lithium, santiago, miner, codelco, cobre, gol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[tariffs, dow, shanghai, trump, billion, stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[brixmor, reuters, commission, ceo, lawsuit, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[investing, bias, overconfidence, herd, return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[robots, racialized, africanamericans, bias, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20190801</td>\n",
       "      <td>[printing, foil, packaging, laminated, anticou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          일자                                                키워드\n",
       "0   20190801  [newspaper, layoffs, buzzfeed, losses, pew, an...\n",
       "1   20190801  [debit, houstonbusiness, ecommerce, p2p, rates...\n",
       "2   20190801  [fintechs, neobankstyle, venture, londonbased,...\n",
       "3   20190801  [nonpayment, invoices, financing, factoring, i...\n",
       "4   20190801  [ippb, postal, delhi, crore, payments, infrast...\n",
       "5   20190801  [goldman, banks, marcus, consumer, markets, br...\n",
       "6   20190801  [inventing, prototypes, changemakers, venture,...\n",
       "7   20190801  [venezuelas, cryptocurrency, sanctions, exchan...\n",
       "8   20190801  [cryptocurrencyfocused, hedge, investing, liqu...\n",
       "9   20190801  [entrepreneurs, purushothaman, newsmarket, fun...\n",
       "10  20190801  [forbes, httpswww, comsiteslizfrazierpeck20190...\n",
       "11  20190801  [entrepreneurship, senegal, smeat, consulting,...\n",
       "12  20190801  [dell, emc, dellemc, recession, merging, share...\n",
       "13  20190801  [sandbox, utahs, wyoming, authorization, requi...\n",
       "14  20190801  [comnewspartnershipsacquisitions2019amexdigita...\n",
       "15  20190801  [cookies, ft, sites, ads, use, secure, data, c...\n",
       "16  20190801  [accountants, exemption, qualifications, chart...\n",
       "17  20190801  [banks, broker, shareholders, refinitivs, reut...\n",
       "18  20190801  [shanghaibased, fanlis, zhu, rebates, venture,...\n",
       "19  20190801  [tuition, institutions, grants, financial, req...\n",
       "20  20190801  [cookies, ft, sites, ads, use, secure, data, c...\n",
       "21  20190801  [audiomasking, eavesdrop, smartphones, mask, s...\n",
       "22  20190801  [airtel, delhibased, bharti, reliance, 2g, cel...\n",
       "23  20190801  [forbes, httpswww, comsitessuzannerowankellehe...\n",
       "24  20190801  [lithium, santiago, miner, codelco, cobre, gol...\n",
       "25  20190801  [tariffs, dow, shanghai, trump, billion, stock...\n",
       "26  20190801  [brixmor, reuters, commission, ceo, lawsuit, d...\n",
       "27  20190801  [investing, bias, overconfidence, herd, return...\n",
       "28  20190801  [robots, racialized, africanamericans, bias, s...\n",
       "29  20190801  [printing, foil, packaging, laminated, anticou..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
